# 사용했던 조합들  
## FPN  
V3+의 문제가 해결되기 이전까지 사용했던 조합들. 여기서 점수를 올렸던 Transform 기법들은 V3+ 넘어가서도 유효했다  
### FPN + ResNet152 + (gridcut+centercrop) + mIoU. mIoU : 0.5580  
FPN의 성능이 나쁘지 않아서 인코더를 resnet시리즈에서 점점 더 무거운 걸로 교체했다.  
이후에는 V3+가 훨씬 성능이 좋음을 알고 encoder보다는 다양한 모델교체를 해서 152까지만 했다.  
### DLV3+ + ResNet152 + Transforms  mIoU : 0.5986, 
안타깝게도 albumentation도 적용하면 장땡이 아니라 점수가 왔다갔다 하더라. 모든 조합의 경우에 대해서
grid search같은게 가능했으면 좋겠지만 시작으로 잡은 0.3이라는 확률이 항상 좋은 결과를 보여줬고 0.5 정도의
확률만 입력해도 점수가 눈에 띄게 감소했다.  
확률값을 입력 할 때 눈에띄게 점수가 증가했던, 혹은 감소했던 transform 들을 적어보다  
#### CenterCrop, CenterCrop(p=0.2,height=300,width=300)  
배경에 대한 독립성을 생각했다. 배경은 대부분 비어있지만 라벨링이 된 경우도 있었다. '바탕은 무조건 비어있다' 라는 편향이 생길법 하고
그것은 잘못된 편향이기에 배경이 라벨링 되어있는 경우와 그렇지 않은 경우를 모두 포함하여 0으로 라벨링 된 배경이라는 요소를 제거하고자 채용하였다.
얘는 딱히 확률값 증가에 따른 영향을 검증하지 않았다. 검토 필요.
#### Flip p=0.3  
얘도 딱히 확률값을 통한 검증은 시도해보지 않았다. 어찌보면 좀 뻔한 카테고리에 속하는 transform 같다.  
#### Gridmask ,GridMask(num_grid=(5),p=0.3,rotate=25)
얘도 딱 보고 효과 있겠다 해서 써봤는데 03에서 05로 확률 증가시키니까 정직하게 성능 추락하는 애였다. 센터크롭과 달리
그리드마스크는 특정 상황에서는 좋을수도, 아닐수도 있는 경우가 명확하게 갈렸기 때문에 seed를 바꿀 경우 점수가 차이가 날 거 같다.
하얀 비닐 위에 네모난 검정 물체는 별도의 mask 일 수 있지만, 작은 갈색 물체와 겹치는 검은 네모는 무늬일수도, 그림자 일수도 있다.
이러한 이유로 p를 증가시키면 잘못된 학습이 입력되는 것 같다. 얘도 grid 사이즈를 바꾸는 실험은 안해봤다.
grid_num의 선정은 플롯 했을 때 너무 작은 무늬같지도, 시야를 가리는 너무 큰 물체 같지도 않은, 자연스럽게 섞일만한 크기의 무언가
 라고 내 눈이 느끼는 크기 정도로 했다. 순전히 감이란 이야기다.

#### Resize  
패딩이나 크롭같은 과정이 포함된 모든 경우는 마지막에 추가로 512512 resize가 필요했다.  

#### IfPadNeeded  
제일 흥미로우면서도 극적인 변화를 가져다 준 transform 이였다. 바탕 크기를 지정 해주면 입력 이미지에서 배경에 모자란 부분마큼
패딩을 해주었고 그 방법이 여러가지가 있었다. 거울모드, 비우기, 늘이기 등... 비우기는 대놓고 성능이 별로였는데, 아마 바탕이 검은색이 아닌 경우에
엄연히 새로운 경계가 생기는데 mask는 그걸 인지 못해서 생기는거 같다. 그래서 그냥 늘이기 정도만 적용했다.

#### 주저리  
transform에 나름 시간을 좀 들이면서 p라는 숫자가 머릿속에서 맴돌았다. 0.5의 트랜스폼 2개를 입력하면 전체 25퍼 정도만
 둘다 적용될까? 그 수치의 분포나 경우의 수는 결과에 영향을 끼칠만한가? 그래서 든 생각은 각각의 transform을
 최소한의 정도만 적용한 여러개의 모델을 hard vote하는건 어떨까 하는 생각이 든다. 지금 양의 효과를 내는 모든 transform을 선을
 지키는 선에서 다 적용하고 있는데, val 점수가 시원찮으면 그냥 있던걸 다 hardvote할까 한다.
 
 ### scheduler  
 이거 효과보기가 너무 빡쎈거 같다. 지금까지 epoch 20으로만 다양한 모델들 검증정도만 했는데, 이게 모델마다 어느 epoch에서 어떤 문제가 생기는지 세심히 관찰을 안했어서 쉽지 않다...
 그래서 수렴구간을 고려해서 이것저것 찾아보고 적용중인데 다들 말한대로 cosine 스케줄러가 제일 낫다. 아마 lr의 감소폭이 급한 구간이 별로 없기 때문인거 같다. lr 하한을 설정하고 전체 epoch을
 주기의 절반으로 줘서  실행중인데... 결과가 어떨지는 봐야 알거 같다.
 
 val : 0.4704  ~ 0.5959
