{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3ddf89-609f-4094-ac5e-cfb6b84aef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.7.1+cu101'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from efficientunet import *\n",
    "from torch.optim import lr_scheduler, Adam, SGD\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pycocotools.coco import COCO\n",
    "import pytorch_msssim\n",
    "\n",
    "import logging\n",
    "import functools\n",
    "import torch._utils\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_all(seed = 42):\n",
    "    \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)  # pytorch (both CPU and CUDA)\n",
    "    np.random.seed(seed)  # for numpy pseudo-random generator\n",
    "    #random.seed(seed)  # set fixed value for python built-in pseudo-random generator\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "seed_all()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "print(device)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fb8285-a5f3-46e1-a366-a474f5675d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "category_names = [\"Backgroud\",\"UNKNOWN\",\"General trash\",\"Paper\",\"Paper pack\",\"Metal\",\"Glass\",\"Plastic\",\"Styrofoam\",\"Plastic bag\",\"Battery\",\"Clothing\"]\n",
    "class_nums = len(category_names)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "        self.ela_aug2 = A.Compose([A.HorizontalFlip(p=0.9), \n",
    "                                  A.VerticalFlip(p=0.9), \n",
    "                                  A.RandomRotate90(p=0.9),\n",
    "                                  A.OneOf([\n",
    "                                    A.MotionBlur(p=1),\n",
    "                                  #  A.OpticalDistortion(p=1),\n",
    "                                  #  A.GaussNoise(p=1),\n",
    "                                    ], p=1),\n",
    "                                   A.ElasticTransform(p=0.9),\n",
    "                                   A.GridDistortion(p=0.9),\n",
    "                                   A.OpticalDistortion(p=0.9),\n",
    "                                   ToTensorV2()])\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        #CLAHE Convert\n",
    "        #images = clahe_cvt(images)\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        #images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "                \n",
    "                if self.mode == 'train' :\n",
    "                    ela2_img = self.ela_aug2(image = images, mask = masks)\n",
    "                    transformed = A.Compose([ToTensorV2()])(image = images, mask = masks)\n",
    "                    images = transformed[\"image\"]\n",
    "                    masks = transformed[\"mask\"]\n",
    "                \n",
    "                    images = (images, ela2_img[\"image\"])#, loc_img[\"image\"])#ela1_img[\"image\"], ela2_img[\"image\"])\n",
    "                    masks = (masks, ela2_img[\"mask\"])#, loc_img[\"mask\"])#ela1_img[\"mask\"], ela2_img[\"mask\"])\n",
    "                \n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                #hor_image = self.test_hor(image = images)[\"image\"]\n",
    "                #ver_image = self.test_ver(image = images)[\"image\"]\n",
    "                \n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "                \n",
    "                #images = (images, hor_image, ver_image)\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())\n",
    "    \n",
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "dataset_path = 'input/data'\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch): return tuple(zip(*batch))\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           #A.CLAHE(),\n",
    "                           #A.Resize(256, 256),\n",
    "                           A.Normalize(\n",
    "                                mean=(0.485, 0.456, 0.406),\n",
    "                                std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0\n",
    "                           ),\n",
    "                           ToTensorV2(),\n",
    "                           ])\n",
    "\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6730de-3dad-40fd-9775-387682a1e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ALIGN_CORNERS = True\n",
    "BN_MOMENTUM = 0.1\n",
    "\n",
    "\n",
    "if torch.__version__.startswith('0'):\n",
    "    from .sync_bn.inplace_abn.bn import InPlaceABNSync\n",
    "    BatchNorm2d = functools.partial(InPlaceABNSync, activation='none')\n",
    "    BatchNorm2d_class = InPlaceABNSync\n",
    "    relu_inplace = False\n",
    "else:\n",
    "    BatchNorm2d_class = BatchNorm2d = torch.nn.SyncBatchNorm\n",
    "    relu_inplace = True\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModuleHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def BNReLU(num_features, bn_type=None, **kwargs):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features, **kwargs),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def BatchNorm2d(*args, **kwargs):\n",
    "        return BatchNorm2d\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class SpatialGather_Module(nn.Module):\n",
    "    \"\"\"\n",
    "        Aggregate the context features according to the initial \n",
    "        predicted probability distribution.\n",
    "        Employ the soft-weighted method to aggregate the context.\n",
    "    \"\"\"\n",
    "    def __init__(self, cls_num=0, scale=1):\n",
    "        super(SpatialGather_Module, self).__init__()\n",
    "        self.cls_num = cls_num\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, feats, probs):\n",
    "        batch_size, c, h, w = probs.size(0), probs.size(1), probs.size(2), probs.size(3)\n",
    "        probs = probs.view(batch_size, c, -1)\n",
    "        feats = feats.view(batch_size, feats.size(1), -1)\n",
    "        feats = feats.permute(0, 2, 1) # batch x hw x c \n",
    "        probs = F.softmax(self.scale * probs, dim=2)# batch x k x hw\n",
    "        ocr_context = torch.matmul(probs, feats)\\\n",
    "        .permute(0, 2, 1).unsqueeze(3)# batch x k x c\n",
    "        return ocr_context\n",
    "\n",
    "\n",
    "class _ObjectAttentionBlock(nn.Module):\n",
    "    '''\n",
    "    The basic implementation for object context block\n",
    "    Input:\n",
    "        N X C X H X W\n",
    "    Parameters:\n",
    "        in_channels       : the dimension of the input feature map\n",
    "        key_channels      : the dimension after the key/query transform\n",
    "        scale             : choose the scale to downsample the input feature maps (save memory cost)\n",
    "        bn_type           : specify the bn type\n",
    "    Return:\n",
    "        N X C X H X W\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(_ObjectAttentionBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.in_channels = in_channels\n",
    "        self.key_channels = key_channels\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(scale, scale))\n",
    "        self.f_pixel = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_object = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_up = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.in_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.in_channels, bn_type=bn_type),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, proxy):\n",
    "        batch_size, h, w = x.size(0), x.size(2), x.size(3)\n",
    "        if self.scale > 1:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        query = self.f_pixel(x).view(batch_size, self.key_channels, -1)\n",
    "        query = query.permute(0, 2, 1)\n",
    "        key = self.f_object(proxy).view(batch_size, self.key_channels, -1)\n",
    "        value = self.f_down(proxy).view(batch_size, self.key_channels, -1)\n",
    "        value = value.permute(0, 2, 1)\n",
    "\n",
    "        sim_map = torch.matmul(query, key)\n",
    "        sim_map = (self.key_channels**-.5) * sim_map\n",
    "        sim_map = F.softmax(sim_map, dim=-1)   \n",
    "\n",
    "        # add bg context ...\n",
    "        context = torch.matmul(sim_map, value)\n",
    "        context = context.permute(0, 2, 1).contiguous()\n",
    "        context = context.view(batch_size, self.key_channels, *x.size()[2:])\n",
    "        context = self.f_up(context)\n",
    "        if self.scale > 1:\n",
    "            context = F.interpolate(input=context, size=(h, w), mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "class ObjectAttentionBlock2D(_ObjectAttentionBlock):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(ObjectAttentionBlock2D, self).__init__(in_channels,\n",
    "                                                     key_channels,\n",
    "                                                     scale, \n",
    "                                                     bn_type=bn_type)\n",
    "\n",
    "\n",
    "class SpatialOCR_Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the OCR module:\n",
    "    We aggregate the global object representation to update the representation for each pixel.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 out_channels, \n",
    "                 scale=1, \n",
    "                 dropout=0.1, \n",
    "                 bn_type=None):\n",
    "        super(SpatialOCR_Module, self).__init__()\n",
    "        self.object_context_block = ObjectAttentionBlock2D(in_channels, \n",
    "                                                           key_channels, \n",
    "                                                           scale, \n",
    "                                                           bn_type)\n",
    "        _in_channels = 2 * in_channels\n",
    "\n",
    "        self.conv_bn_dropout = nn.Sequential(\n",
    "            nn.Conv2d(_in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(out_channels, bn_type=bn_type),\n",
    "            nn.Dropout2d(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, feats, proxy_feats):\n",
    "        context = self.object_context_block(feats, proxy_feats)\n",
    "\n",
    "        output = self.conv_bn_dropout(torch.cat([context, feats], 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion,\n",
    "                               momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.num_inchannels[branch_index],\n",
    "                          num_channels[branch_index] * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
    "                            momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index],\n",
    "                            num_channels[branch_index], stride, downsample))\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index],\n",
    "                                num_channels[branch_index]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j],\n",
    "                                  num_inchannels[i],\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  0,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM)))\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM),\n",
    "                                nn.ReLU(inplace=relu_inplace)))\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                elif j > i:\n",
    "                    width_output = x[i].shape[-1]\n",
    "                    height_output = x[i].shape[-2]\n",
    "                    y = y + F.interpolate(\n",
    "                        self.fuse_layers[i][j](x[j]),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse\n",
    "\n",
    "\n",
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}\n",
    "\n",
    "\n",
    "class HighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        global ALIGN_CORNERS\n",
    "        super(HighResolutionNet, self).__init__()\n",
    "        extra = config['MODEL']['EXTRA']\n",
    "        ALIGN_CORNERS = config['MODEL']['ALIGN_CORNERS']\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "\n",
    "        self.stage1_cfg = extra['STAGE1']\n",
    "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
    "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
    "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
    "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
    "        stage1_out_channel = block.expansion*num_channels\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer(\n",
    "            [stage1_out_channel], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "\n",
    "        last_inp_channels = np.int(np.sum(pre_stage_channels))\n",
    "        ocr_mid_channels = config['MODEL']['OCR']['MID_CHANNELS']\n",
    "        ocr_key_channels = config['MODEL']['OCR']['KEY_CHANNELS']\n",
    "\n",
    "        self.conv3x3_ocr = nn.Sequential(\n",
    "            nn.Conv2d(last_inp_channels, ocr_mid_channels,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(ocr_mid_channels),\n",
    "            nn.ReLU(inplace=relu_inplace),\n",
    "        )\n",
    "        self.ocr_gather_head = SpatialGather_Module(config['DATASET']['NUM_CLASSES'])\n",
    "\n",
    "        self.ocr_distri_head = SpatialOCR_Module(in_channels=ocr_mid_channels,\n",
    "                                                 key_channels=ocr_key_channels,\n",
    "                                                 out_channels=ocr_mid_channels,\n",
    "                                                 scale=1,\n",
    "                                                 dropout=0.05,\n",
    "                                                 )\n",
    "        self.cls_head = nn.Conv2d(\n",
    "            ocr_mid_channels, config['DATASET']['NUM_CLASSES'], kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Conv2d(last_inp_channels, last_inp_channels,\n",
    "                      kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(last_inp_channels),\n",
    "            nn.ReLU(inplace=relu_inplace),\n",
    "            nn.Conv2d(last_inp_channels, config['DATASET']['NUM_CLASSES'],\n",
    "                      kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        )\n",
    "        \n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i],\n",
    "                                  num_channels_cur_layer[i],\n",
    "                                  3,\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(\n",
    "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=relu_inplace)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(\n",
    "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=relu_inplace)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "            modules.append(\n",
    "                HighResolutionModule(num_branches,\n",
    "                                     block,\n",
    "                                     num_blocks,\n",
    "                                     num_inchannels,\n",
    "                                     num_channels,\n",
    "                                     fuse_method,\n",
    "                                     reset_multi_scale_output)\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                if i < self.stage2_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition2[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                if i < self.stage3_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition3[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        x = self.stage4(x_list)\n",
    "\n",
    "        # Upsampling\n",
    "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
    "        x1 = F.interpolate(x[1], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "        x2 = F.interpolate(x[2], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "        x3 = F.interpolate(x[3], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        feats = torch.cat([x[0], x1, x2, x3], 1)\n",
    "\n",
    "        out_aux_seg = []\n",
    "\n",
    "        # ocr\n",
    "        out_aux = self.aux_head(feats)\n",
    "        # compute contrast feature\n",
    "        feats = self.conv3x3_ocr(feats)\n",
    "\n",
    "        context = self.ocr_gather_head(feats, out_aux)\n",
    "        feats = self.ocr_distri_head(feats, context)\n",
    "\n",
    "        out = self.cls_head(feats)\n",
    "\n",
    "        out_aux_seg.append(out_aux)\n",
    "        out_aux_seg.append(out)\n",
    "\n",
    "        return out_aux_seg\n",
    "\n",
    "    def init_weights(self, pretrained='',):\n",
    "        logger.info('=> init weights from normal distribution')\n",
    "        for name, m in self.named_modules():\n",
    "            if any(part in name for part in {'cls', 'aux', 'ocr'}):\n",
    "                # print('skipped', name)\n",
    "                continue\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "            elif isinstance(m, BatchNorm2d_class):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained, map_location={'cuda:0': 'cpu'})\n",
    "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k.replace('last_layer', 'aux_head').replace('model.', ''): v for k, v in pretrained_dict.items()}            \n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                               if k in model_dict.keys()}\n",
    "            # for k, _ in pretrained_dict.items():\n",
    "                # logger.info(\n",
    "                #     '=> loading {} pretrained model {}'.format(k, pretrained))\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "        elif pretrained:\n",
    "            raise RuntimeError('No such file {}'.format(pretrained))\n",
    "\n",
    "\n",
    "def get_seg_model(cfg, **kwargs):\n",
    "    model = HighResolutionNet(cfg, **kwargs)\n",
    "    #model.init_weights(cfg['MODEL']['PRETRAINED'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, config, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label\n",
    "        )\n",
    "        self.config = config\n",
    "        self.focal_loss = FocalLoss()\n",
    "\n",
    "    def _forward(self, score, target):\n",
    "        ph, pw = score.size(2), score.size(3)\n",
    "        h, w = target.size(1), target.size(2)\n",
    "        if ph != h or pw != w:\n",
    "            score = F.interpolate(input=score, size=(\n",
    "                h, w), mode='bilinear', align_corners=self.config['MODEL']['ALIGN_CORNERS'])\n",
    "\n",
    "        cross_loss = self.criterion(score, target)\n",
    "        focal_loss = self.focal_loss(score, target)\n",
    "        loss = 0.9*cross_loss+0.1*focal_loss\n",
    "        return loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if self.config['MODEL']['NUM_OUTPUTS'] == 1:\n",
    "            score = [score]\n",
    "\n",
    "        weights = self.config['LOSS']['BALANCE_WEIGHTS']\n",
    "        assert len(weights) == len(score)\n",
    "\n",
    "        return sum([w * self._forward(x, target) for (w, x) in zip(weights, score)])\n",
    "\n",
    "    \n",
    "\n",
    "import yaml\n",
    "\n",
    "def model_loss_define(yaml_path, train=True):\n",
    "    with open(yaml_path) as f:\n",
    "        cfg = yaml.load(f)\n",
    "\n",
    "    model = get_seg_model(cfg)\n",
    "    creterion = CrossEntropy(cfg)\n",
    "    return model, creterion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7a574-8006-4ade-8da8-27e4b7cf2469",
   "metadata": {},
   "source": [
    "#### SoftVote\n",
    "\n",
    "1) 전체 모델에 대해\n",
    "\n",
    "    1-1) 최고 모델 + 0.1 / 최저 모델 - 0.1\n",
    " \n",
    "    1-2) 최고 모델 0.0, 그 다음부터 -0.05씩\n",
    " \n",
    "    1-3) 상위 3개 모델에만 0.4\n",
    " \n",
    "    1-4) 최고 모델에만 0.5\n",
    " \n",
    "    1-5) 가중치 없이\n",
    " \n",
    " \n",
    "2) 상위 3개\n",
    "\n",
    "     2-1) 최고 모델 + 0.1 / 최저 모델 - 0.1\n",
    " \n",
    "     2-2) 최고 모델 0.0, 그 다음부터 -0.05씩\n",
    " \n",
    "     2-3) 최고 모델에만 0.5\n",
    " \n",
    "     2-4) 가중치 없이\n",
    " \n",
    " \n",
    "3) 최고 점수 기준 -0.01\n",
    "\n",
    "     3-1) 최고 모델 + 0.1 / 최저 모델 - 0.1\n",
    "     \n",
    "     3-2) 최고 모델 0.0, 그 다음부터 -0.05씩\n",
    " \n",
    "     3-3) 최고 모델에만 0.5\n",
    " \n",
    "     3-4) 가중치 없이\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47db5593-fb2f-44fc-bd5e-4680f314ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SoftVote\n",
    "def multi_model_ensemble_test (models, weights, dataloader, device, hrn=9999999) :\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    for model in models :\n",
    "        model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    #file_list_\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in tqdm(enumerate(test_loader)) :\n",
    "            x = torch.stack(imgs).to(device)\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = models[0](x) * weights[0]\n",
    "            isFirst = True\n",
    "            for model_step, (model, weight) in enumerate(zip(models, weights)) :\n",
    "                if isFirst :\n",
    "                    isFirst = False\n",
    "                else :\n",
    "                    if model_step == hrn :\n",
    "                        predict = model(x)[1]\n",
    "                        predict = F.interpolate(input = predict, size = (512, 512), mode = 'bilinear', align_corners = True)\n",
    "                        outs += predict * weight\n",
    "                    else :\n",
    "                        outs += model(x) * weight\n",
    "            \n",
    "            if outs.shape[0] == 1 : oms = torch.argmax(outs.squeeze(), dim = 0).detach().cpu().numpy()\n",
    "            else : oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "            \n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d144f7e1-964c-4e6a-9e42-84f1e4061a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [20:37, 23.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n",
      "soft_vote_1_1 is saved!\n",
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [20:48, 23.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n",
      "soft_vote_1_2 is saved!\n",
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [20:49, 23.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n",
      "soft_vote_1_3 is saved!\n",
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [20:45, 23.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n",
      "soft_vote_1_4 is saved!\n",
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [20:41, 23.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n",
      "soft_vote_1_5 is saved!\n"
     ]
    }
   ],
   "source": [
    "#---------------------1-1\n",
    "\n",
    "models = list()\n",
    "weights = list()\n",
    "dir_name = \"./Camper_models/\"\n",
    "for i, model_name in enumerate([\"dv3p_16batch_adamp_512_cos.pt\",\\\n",
    "                                \"dv3p_16batch_adamp_512.pt\",\\\n",
    "                                \"dv3p_16batch_adamp_512_full.pt\",\\\n",
    "                                \"dv3p_16batch_adamp_512_red.pt\",\\\n",
    "                                \"Final9.pt\",\\\n",
    "                                \"Final4.pt\",\\\n",
    "                                \"effib4_elatrans.pt\",\\\n",
    "                                \"effib4_cross_label_focal.pt\",\\\n",
    "                                \"DLV3P_res152_5989.pt\",\\\n",
    "                                \"DLV3P_res152_5959.pt\",\\\n",
    "                                \"dv3p_16batch_adamp_512_wsj.pt\"\n",
    "                  ]) :\n",
    "    model_name = dir_name + model_name\n",
    "    if i < 4 :\n",
    "        model = smp.DeepLabV3Plus(\n",
    "                    encoder_name='resnext101_32x4d',\n",
    "                    encoder_weights = 'ssl',\n",
    "                    classes = class_nums).to(device)\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "    elif i < 6 :\n",
    "        model = smp.DeepLabV3Plus(\n",
    "                encoder_name='timm-regnety_032',\n",
    "                encoder_weights = 'imagenet',\n",
    "                classes = class_nums).to(device)\n",
    "        model.load_state_dict(torch.load(model_name)['net'])\n",
    "    elif i < 8 :\n",
    "        model = smp.DeepLabV3Plus(encoder_name=\"timm-efficientnet-b4\",\n",
    "                          encoder_weights=\"noisy-student\",\n",
    "                          classes=class_nums).to(device)\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "    elif i < 10 :\n",
    "        model = smp.DeepLabV3Plus(\n",
    "                    encoder_name='resnet152',\n",
    "                    encoder_weights = 'imagenet',\n",
    "                    classes = class_nums).to(device)\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "    else :\n",
    "        model, _ = model_loss_define('/opt/ml/code/seg_hrnet.yaml')\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "        \n",
    "    models.append(model)\n",
    "    weights.append(1)\n",
    "\n",
    "#가중치 추가\n",
    "weights[0] += 0.1\n",
    "weights[len(models) - 1] -= 0.1\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device, hrn = 10)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_1_1\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "#-------------1-2\n",
    "\n",
    "weights[0] = 1\n",
    "weights[len(models) - 1] = 1\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = weight - (0.05 * i)\n",
    "    if weights[i] < 0 : weights[i] = 0\n",
    "\n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device, hrn = 10)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_1_2\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "\n",
    "#-------------1-3\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "\n",
    "weights[0] += 0.4\n",
    "weights[1] += 0.4\n",
    "weights[2] += 0.4\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device, hrn = 10)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_1_3\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "\n",
    "#-------------1-4\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "\n",
    "weights[0] += 0.5\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device, hrn = 10)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_1_4\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "#-------------1-5\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device, hrn = 10)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_1_5\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8f049-c80a-4c24-9bab-3ff418ce0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------2-1\n",
    "\n",
    "models = list()\n",
    "weights = list()\n",
    "dir_name = \"./Camper_models/\"\n",
    "for model_name in [\"dv3p_16batch_adamp_512_cos.pt\",\\\n",
    "                  \"dv3p_16batch_adamp_512.pt\",\\\n",
    "                  \"dv3p_16batch_adamp_512_full.pt\"\n",
    "                  ] :\n",
    "    model_name = dir_name + model_name\n",
    "    model = smp.DeepLabV3Plus(\n",
    "                encoder_name='resnext101_32x4d',\n",
    "                encoder_weights = 'ssl',\n",
    "                classes = class_nums).to(device)\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    models.append(model)\n",
    "    weights.append(1)\n",
    "\n",
    "#가중치 추가\n",
    "weights[0] += 0.1\n",
    "weights[len(models) - 1] -= 0.1\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_2_1\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "#---------------------2-2\n",
    "\n",
    "weights[0] = 1\n",
    "weights[len(models) - 1] = 1\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = weight - (0.05 * i)\n",
    "\n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_2_2\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "\n",
    "#-------------2-3\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "\n",
    "weights[0] += 0.5\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_2_3\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "#-------------2-4\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_2_4\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa9e14-f0bc-4bb2-970c-2185e15daece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------3-1\n",
    "\n",
    "models = list()\n",
    "weights = list()\n",
    "dir_name = \"./Camper_models/\"\n",
    "for model_name in [\"dv3p_16batch_adamp_512_cos.pt\",\\\n",
    "                  \"dv3p_16batch_adamp_512.pt\",\\\n",
    "                  \"dv3p_16batch_adamp_512_full.pt\",\\\n",
    "                   \"dv3p_16batch_adamp_512_red.pt\"\n",
    "                  ] :\n",
    "    model_name = dir_name + model_name\n",
    "    model = smp.DeepLabV3Plus(\n",
    "                encoder_name='resnext101_32x4d',\n",
    "                encoder_weights = 'ssl',\n",
    "                classes = class_nums).to(device)\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    models.append(model)\n",
    "    weights.append(1)\n",
    "\n",
    "#가중치 추가\n",
    "weights[0] += 0.1\n",
    "weights[len(models) - 1] -= 0.1\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_3_1\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "#---------------------3-2\n",
    "\n",
    "weights[0] = 1\n",
    "weights[len(models) - 1] = 1\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = weight - (0.05 * i)\n",
    "    if weights[i] < 0 : weights[i] = 0\n",
    "\n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_3_2\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "\n",
    "#-------------3-3\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "\n",
    "weights[0] += 0.5\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_3_3\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')\n",
    "\n",
    "#-------------3-4\n",
    "\n",
    "for i, weight in enumerate(weights) :\n",
    "    weights[i] = 1\n",
    "    \n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = multi_model_ensemble_test(models, weights, test_loader, device)\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "save_name = \"soft_vote_3_4\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "print(save_name, 'is saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98b9f0-1135-4865-85f0-fe162ade3a80",
   "metadata": {},
   "source": [
    "#### HardVote\n",
    "\n",
    "1) 전체 출력물\n",
    "\n",
    "    1-1) 가중치 없이 그냥\n",
    "    \n",
    "    1-2) 상위 3개의 만장일치에 우선순위\n",
    "    \n",
    "    1-3) 가중치 부여 (상위부터 0.3, 0.2, 0.1, 0.0, 0.0, ... ,0.0)\n",
    "    \n",
    "2) -0.005까지의 결과물들\n",
    "\n",
    "    2-1) 가중치 없이 그냥\n",
    "    \n",
    "    2-2) 상위 3개의 만장일치에 우선순위\n",
    "\n",
    "    2-3) 가중치 부여 (상위부터 0.3, 0.2, 0.1, 0.0, 0.0, ... ,0.0)\n",
    "\n",
    "3) -0.01까지의 결과물들\n",
    "\n",
    "    3-1) 가중치 없이 그냥\n",
    "    \n",
    "    3-2) 상위 3개의 만장일치에 우선순위\n",
    "    \n",
    "    3-3) 가중치 부여 (상위부터 0.3, 0.2, 0.1, 0.0, 0.0, ... ,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b326747f-724e-4e12-b517-0f057c2d53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def hard_vote_models (csv_files, best_model, isSecond = False, isHasWeights = False, weights = None) :\n",
    "    out_submission = pd.DataFrame(columns=[\"image_id\", \"PredictionString\"])\n",
    "    out_submission[\"image_id\"] = csv_files[0][\"image_id\"]\n",
    "    #print(out_submission.head())\n",
    "    \n",
    "    whole_prediction = list()\n",
    "    for i in tqdm(range(len(csv_files[0]))) :\n",
    "        predict_arr = np.zeros(256*256)\n",
    "        predict_arr_tmp = np.zeros((256*256, 12))\n",
    "        \n",
    "        for k, csv_file in enumerate(csv_files) :\n",
    "            #print(csv_file.iloc[i])\n",
    "            predict = csv_file.iloc[i][\"PredictionString\"]\n",
    "            predict = predict.split()\n",
    "            \n",
    "            for j, pixel_predict in enumerate(predict) :\n",
    "                if isHasWeights : \n",
    "                    predict_arr_tmp[j][eval(pixel_predict)] += 1 * weights[k]\n",
    "                else :\n",
    "                    predict_arr_tmp[j][eval(pixel_predict)] += 1\n",
    "            \n",
    "        for j, _ in enumerate(predict_arr_tmp) :\n",
    "            max_index = np.argmax(predict_arr_tmp[j])\n",
    "            max_index_size = np.where(predict_arr_tmp[j] == predict_arr_tmp[j][max_index])\n",
    "            #print(max_index_size)\n",
    "            if isSecond :\n",
    "                if len(max_index_size) == 1 :\n",
    "                    predict_arr[j] = max_index\n",
    "                elif csv_files[0].iloc[i].split()[j] == csv_files[1].iloc[i].split()[j] and csv_files[0].iloc[i].split()[j] == csv_files[2].iloc[i].split()[j] :\n",
    "                    predict_arr[j] = csv_files[0].iloc[i].split()[j]\n",
    "                elif csv_files[best_model].iloc[i].split()[j] in max_index_size :\n",
    "                    predict_arr[j] = csv_files[best_model].iloc[i].split()[j]\n",
    "                else :\n",
    "                    predict_arr[j] = random.choice(max_index_size)\n",
    "            else :\n",
    "                if len(max_index_size) == 1 :\n",
    "                    predict_arr[j] = max_index\n",
    "                elif csv_files[best_model].iloc[i].split()[j] in max_index_size :\n",
    "                    predict_arr[j] = csv_files[best_model].iloc[i].split()[j]\n",
    "                else :\n",
    "                    predict_arr[j] = random.choice(max_index_size)\n",
    "                \n",
    "        whole_prediction.append(' '.join(str(int(e)) for e in predict_arr.tolist()))\n",
    "    \n",
    "    out_submission[\"PredictionString\"] = whole_prediction\n",
    "    return out_submission\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a71b49-2a6f-430c-8f0c-145f3b90a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 80/837 [07:33<1:12:15,  5.73s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "sub_dir = \"./Camper_submissions/\"\n",
    "files = [\"output.csv\", \\\n",
    "         \"soft_vote_3_2.csv\", \\\n",
    "         \"output (1).csv\", \\\n",
    "         \"soft_vote_2_1.csv\", \\\n",
    "         \"output (2).csv\",\\\n",
    "         \"soft_vote_2_2.csv\", \\\n",
    "         \"soft_vote_3_3.csv\", \\\n",
    "         \"soft_vote_3_4.csv\", \\\n",
    "         \"soft_vote_2_3.csv\", \\\n",
    "         \"soft_vote_2_4.csv\", \\\n",
    "         \"ensemble.csv\", \\\n",
    "         \"hardvote_ensemble2.csv\", \\\n",
    "         \"ensemble1.csv\",\\\n",
    "         \"hardvote_ensemble1.csv\", \\\n",
    "         \"output (3).csv\", \\\n",
    "        ]\n",
    "\n",
    "for i, file in enumerate(files) :\n",
    "    files[i] = pd.read_csv(sub_dir + file)\n",
    "#-----------------1-1\n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0) \n",
    "save_name = \"hard_vote_1_1\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "\n",
    "#-----------------1-2\n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0, isSecond = True) \n",
    "save_name = \"hard_vote_1_2\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "\n",
    "#-----------------1-3\n",
    "weights = list()\n",
    "\n",
    "for i, file in enumerate(files) :\n",
    "    weight = 1 + 0.1*(3-i)\n",
    "    if weight <= 1 : weight = 1\n",
    "    weights.append(weight)\n",
    "    \n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0, isHasWeights = True, weights=weights) \n",
    "save_name = \"hard_vote_1_3\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98834502-bfbe-4ff9-9a33-a1c7eb09fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------2-1\n",
    "sub_dir = \"./Camper_submissions/\"\n",
    "files = [\"output.csv\", \\\n",
    "         \"soft_vote_3_2.csv\", \\\n",
    "         \"output (1).csv\"]\n",
    "\n",
    "for i, file in enumerate(files) :\n",
    "    files[i] = pd.read_csv(sub_dir + file)\n",
    "    \n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0) \n",
    "save_name = \"hard_vote_2_1\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "\n",
    "#-----------------2-2\n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0, isSecond = True) \n",
    "save_name = \"hard_vote_2_2\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "\n",
    "#-----------------2-3\n",
    "weights = list()\n",
    "\n",
    "for i, file in enumerate(files) :\n",
    "    weight = 1 + 0.1*(3-i)\n",
    "    if weight <= 1 : weight = 1\n",
    "    weights.append(weight)\n",
    "    \n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0, isHasWeights = True, weights=weights) \n",
    "save_name = \"hard_vote_2_3\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3518b0-b9df-4bc5-88be-9fc395716a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------3-1\n",
    "sub_dir = \"./Camper_submissions/\"\n",
    "files = [\"output.csv\", \\\n",
    "         \"soft_vote_3_2.csv\", \\\n",
    "         \"output (1).csv\", \\\n",
    "         \"soft_vote_2_1.csv\", \\\n",
    "         \"output (2).csv\",\\\n",
    "         \"soft_vote_2_2.csv\", \\\n",
    "         \"soft_vote_3_3.csv\", \\\n",
    "         \"soft_vote_3_4.csv\", \\\n",
    "         \"soft_vote_2_3.csv\", \\\n",
    "         \"soft_vote_2_4.csv\"]\n",
    "\n",
    "for i, file in enumerate(files) :\n",
    "    files[i] = pd.read_csv(sub_dir + file)\n",
    "    \n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0) \n",
    "save_name = \"hard_vote_3_1\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "\n",
    "#-----------------3-2\n",
    "    \n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0, isSecond = True) \n",
    "save_name = \"hard_vote_3_2\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)\n",
    "\n",
    "#-----------------3-3\n",
    "\n",
    "weights = list()\n",
    "\n",
    "for i, file in enumerate(files) :\n",
    "    files[i] = pd.read_csv(sub_dir + file)\n",
    "    weight = 1 + 0.1*(3-i)\n",
    "    if weight <= 1 : weight = 1\n",
    "    weights.append(weight)\n",
    "    \n",
    "#파라미터 중 0 은 가장 좋은 모델의 index입니다. => 중복된 투표 수를 가진 항목들에 대해 가장 좋은 모델의 선택을 따를 예정.\n",
    "submission = hard_vote_models(files, 0, isHasWeights = True, weights=weights) \n",
    "save_name = \"hard_vote_3_3\"\n",
    "submission.to_csv(\"./ensemble_result/\"+save_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447674d-e28b-4670-b7d7-d7b13ae1e4b0",
   "metadata": {},
   "source": [
    "##### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d49f6-0d76-470b-ba7e-a1b66e49bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "index = 5 #이거 바꿔가면서 실행해서 너무 같은 값만 나오지 않는 지 확인해주세요!\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_1_1.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_1_1')\n",
    "print(arr)\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_1_2.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_1_2')\n",
    "print(arr)\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_1_3.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_1_3')\n",
    "print(arr)\n",
    "\n",
    "#------------2번 하신 분은 여기만\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_2_1.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('softvote_2_1')\n",
    "print(arr)\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_2_2.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_2_2')\n",
    "print(arr)\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_2_3.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_2_3')\n",
    "print(arr)\n",
    "\n",
    "#--------------3번 하신 분은 여기만\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_3_1.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('softvote_3_1')\n",
    "print(arr)\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_3_2.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_3_2')\n",
    "print(arr)\n",
    "\n",
    "sub = pd.read_csv('ensemble_result/hard_vote_3_3.csv')\n",
    "s = sub.iloc[index][\"PredictionString\"]\n",
    "\n",
    "arr = np.zeros(12)\n",
    "for ss in s.split() :\n",
    "    arr[int(ss)] += 1\n",
    "print('hardvote_3_3')\n",
    "print(arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
