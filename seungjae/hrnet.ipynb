{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4eb1593-77f6-47fa-958b-f7142e74a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease                     \n",
      "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease           \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease         \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "libxrender-dev is already the newest version (1:0.9.10-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.19.5)\n",
      "Requirement already satisfied: apex in /opt/conda/lib/python3.7/site-packages (0.9.10.dev0)\n",
      "Requirement already satisfied: pyramid>1.1.2 in /opt/conda/lib/python3.7/site-packages (from apex) (2.0)\n",
      "Requirement already satisfied: cryptacular in /opt/conda/lib/python3.7/site-packages (from apex) (1.5.5)\n",
      "Requirement already satisfied: wtforms in /opt/conda/lib/python3.7/site-packages (from apex) (2.3.3)\n",
      "Requirement already satisfied: wtforms-recaptcha in /opt/conda/lib/python3.7/site-packages (from apex) (0.3.2)\n",
      "Requirement already satisfied: velruse>=1.0.3 in /opt/conda/lib/python3.7/site-packages (from apex) (1.1.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from apex) (2.23.0)\n",
      "Requirement already satisfied: pyramid-mailer in /opt/conda/lib/python3.7/site-packages (from apex) (0.15.1)\n",
      "Requirement already satisfied: zope.sqlalchemy in /opt/conda/lib/python3.7/site-packages (from apex) (1.4)\n",
      "Requirement already satisfied: hupper>=1.5 in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (1.10.2)\n",
      "Requirement already satisfied: webob>=1.8.3 in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (1.8.7)\n",
      "Requirement already satisfied: translationstring>=0.4 in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (1.4)\n",
      "Requirement already satisfied: zope.interface>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (5.4.0)\n",
      "Requirement already satisfied: plaster in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (46.4.0.post20200518)\n",
      "Requirement already satisfied: zope.deprecation>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (4.4.0)\n",
      "Requirement already satisfied: venusian>=1.0 in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (3.0.0)\n",
      "Requirement already satisfied: plaster-pastedeploy in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex) (0.7)\n",
      "Requirement already satisfied: pbkdf2 in /opt/conda/lib/python3.7/site-packages (from cryptacular->apex) (1.3)\n",
      "Requirement already satisfied: MarkupSafe in /opt/conda/lib/python3.7/site-packages (from wtforms->apex) (1.1.1)\n",
      "Requirement already satisfied: anykeystore in /opt/conda/lib/python3.7/site-packages (from velruse>=1.0.3->apex) (0.2)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from velruse>=1.0.3->apex) (1.3.0)\n",
      "Requirement already satisfied: python3-openid in /opt/conda/lib/python3.7/site-packages (from velruse>=1.0.3->apex) (3.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->apex) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->apex) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->apex) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->apex) (2020.12.5)\n",
      "Requirement already satisfied: repoze.sendmail>=4.1 in /opt/conda/lib/python3.7/site-packages (from pyramid-mailer->apex) (4.4.1)\n",
      "Requirement already satisfied: transaction in /opt/conda/lib/python3.7/site-packages (from pyramid-mailer->apex) (3.0.1)\n",
      "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9 in /opt/conda/lib/python3.7/site-packages (from zope.sqlalchemy->apex) (1.4.11)\n",
      "Requirement already satisfied: PasteDeploy>=2.0 in /opt/conda/lib/python3.7/site-packages (from plaster-pastedeploy->pyramid>1.1.2->apex) (2.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex) (3.4.1)\n",
      "Requirement already satisfied: torchsummary in /opt/conda/lib/python3.7/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libsm6 libxext6 libxrender-dev\n",
    "!pip install opencv-python\n",
    "!pip install apex\n",
    "!pip install torchsummary\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import functools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch._utils\n",
    "import torch.nn.functional as F\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae558131-ead7-4d4f-a8d0-3cdb8740b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "ALIGN_CORNERS = True\n",
    "BN_MOMENTUM = 0.1\n",
    "\n",
    "\n",
    "if torch.__version__.startswith('0'):\n",
    "    from .sync_bn.inplace_abn.bn import InPlaceABNSync\n",
    "    BatchNorm2d = functools.partial(InPlaceABNSync, activation='none')\n",
    "    BatchNorm2d_class = InPlaceABNSync\n",
    "    relu_inplace = False\n",
    "else:\n",
    "    BatchNorm2d_class = BatchNorm2d = torch.nn.SyncBatchNorm\n",
    "    relu_inplace = True\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModuleHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def BNReLU(num_features, bn_type=None, **kwargs):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features, **kwargs),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def BatchNorm2d(*args, **kwargs):\n",
    "        return BatchNorm2d\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class SpatialGather_Module(nn.Module):\n",
    "    \"\"\"\n",
    "        Aggregate the context features according to the initial \n",
    "        predicted probability distribution.\n",
    "        Employ the soft-weighted method to aggregate the context.\n",
    "    \"\"\"\n",
    "    def __init__(self, cls_num=0, scale=1):\n",
    "        super(SpatialGather_Module, self).__init__()\n",
    "        self.cls_num = cls_num\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, feats, probs):\n",
    "        batch_size, c, h, w = probs.size(0), probs.size(1), probs.size(2), probs.size(3)\n",
    "        probs = probs.view(batch_size, c, -1)\n",
    "        feats = feats.view(batch_size, feats.size(1), -1)\n",
    "        feats = feats.permute(0, 2, 1) # batch x hw x c \n",
    "        probs = F.softmax(self.scale * probs, dim=2)# batch x k x hw\n",
    "        ocr_context = torch.matmul(probs, feats)\\\n",
    "        .permute(0, 2, 1).unsqueeze(3)# batch x k x c\n",
    "        return ocr_context\n",
    "\n",
    "\n",
    "class _ObjectAttentionBlock(nn.Module):\n",
    "    '''\n",
    "    The basic implementation for object context block\n",
    "    Input:\n",
    "        N X C X H X W\n",
    "    Parameters:\n",
    "        in_channels       : the dimension of the input feature map\n",
    "        key_channels      : the dimension after the key/query transform\n",
    "        scale             : choose the scale to downsample the input feature maps (save memory cost)\n",
    "        bn_type           : specify the bn type\n",
    "    Return:\n",
    "        N X C X H X W\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(_ObjectAttentionBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.in_channels = in_channels\n",
    "        self.key_channels = key_channels\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(scale, scale))\n",
    "        self.f_pixel = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_object = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_up = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.in_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.in_channels, bn_type=bn_type),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, proxy):\n",
    "        batch_size, h, w = x.size(0), x.size(2), x.size(3)\n",
    "        if self.scale > 1:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        query = self.f_pixel(x).view(batch_size, self.key_channels, -1)\n",
    "        query = query.permute(0, 2, 1)\n",
    "        key = self.f_object(proxy).view(batch_size, self.key_channels, -1)\n",
    "        value = self.f_down(proxy).view(batch_size, self.key_channels, -1)\n",
    "        value = value.permute(0, 2, 1)\n",
    "\n",
    "        sim_map = torch.matmul(query, key)\n",
    "        sim_map = (self.key_channels**-.5) * sim_map\n",
    "        sim_map = F.softmax(sim_map, dim=-1)   \n",
    "\n",
    "        # add bg context ...\n",
    "        context = torch.matmul(sim_map, value)\n",
    "        context = context.permute(0, 2, 1).contiguous()\n",
    "        context = context.view(batch_size, self.key_channels, *x.size()[2:])\n",
    "        context = self.f_up(context)\n",
    "        if self.scale > 1:\n",
    "            context = F.interpolate(input=context, size=(h, w), mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "class ObjectAttentionBlock2D(_ObjectAttentionBlock):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(ObjectAttentionBlock2D, self).__init__(in_channels,\n",
    "                                                     key_channels,\n",
    "                                                     scale, \n",
    "                                                     bn_type=bn_type)\n",
    "\n",
    "\n",
    "class SpatialOCR_Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the OCR module:\n",
    "    We aggregate the global object representation to update the representation for each pixel.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 out_channels, \n",
    "                 scale=1, \n",
    "                 dropout=0.1, \n",
    "                 bn_type=None):\n",
    "        super(SpatialOCR_Module, self).__init__()\n",
    "        self.object_context_block = ObjectAttentionBlock2D(in_channels, \n",
    "                                                           key_channels, \n",
    "                                                           scale, \n",
    "                                                           bn_type)\n",
    "        _in_channels = 2 * in_channels\n",
    "\n",
    "        self.conv_bn_dropout = nn.Sequential(\n",
    "            nn.Conv2d(_in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(out_channels, bn_type=bn_type),\n",
    "            nn.Dropout2d(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, feats, proxy_feats):\n",
    "        context = self.object_context_block(feats, proxy_feats)\n",
    "\n",
    "        output = self.conv_bn_dropout(torch.cat([context, feats], 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion,\n",
    "                               momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.num_inchannels[branch_index],\n",
    "                          num_channels[branch_index] * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
    "                            momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index],\n",
    "                            num_channels[branch_index], stride, downsample))\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index],\n",
    "                                num_channels[branch_index]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j],\n",
    "                                  num_inchannels[i],\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  0,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM)))\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM),\n",
    "                                nn.ReLU(inplace=relu_inplace)))\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                elif j > i:\n",
    "                    width_output = x[i].shape[-1]\n",
    "                    height_output = x[i].shape[-2]\n",
    "                    y = y + F.interpolate(\n",
    "                        self.fuse_layers[i][j](x[j]),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse\n",
    "\n",
    "\n",
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}\n",
    "\n",
    "\n",
    "class HighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        global ALIGN_CORNERS\n",
    "        super(HighResolutionNet, self).__init__()\n",
    "        extra = config['MODEL']['EXTRA']\n",
    "        ALIGN_CORNERS = config['MODEL']['ALIGN_CORNERS']\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "\n",
    "        self.stage1_cfg = extra['STAGE1']\n",
    "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
    "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
    "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
    "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
    "        stage1_out_channel = block.expansion*num_channels\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer(\n",
    "            [stage1_out_channel], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "\n",
    "        last_inp_channels = np.int(np.sum(pre_stage_channels))\n",
    "        ocr_mid_channels = config['MODEL']['OCR']['MID_CHANNELS']\n",
    "        ocr_key_channels = config['MODEL']['OCR']['KEY_CHANNELS']\n",
    "\n",
    "        self.conv3x3_ocr = nn.Sequential(\n",
    "            nn.Conv2d(last_inp_channels, ocr_mid_channels,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(ocr_mid_channels),\n",
    "            nn.ReLU(inplace=relu_inplace),\n",
    "        )\n",
    "        self.ocr_gather_head = SpatialGather_Module(config['DATASET']['NUM_CLASSES'])\n",
    "\n",
    "        self.ocr_distri_head = SpatialOCR_Module(in_channels=ocr_mid_channels,\n",
    "                                                 key_channels=ocr_key_channels,\n",
    "                                                 out_channels=ocr_mid_channels,\n",
    "                                                 scale=1,\n",
    "                                                 dropout=0.05,\n",
    "                                                 )\n",
    "        self.cls_head = nn.Conv2d(\n",
    "            ocr_mid_channels, config['DATASET']['NUM_CLASSES'], kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Conv2d(last_inp_channels, last_inp_channels,\n",
    "                      kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(last_inp_channels),\n",
    "            nn.ReLU(inplace=relu_inplace),\n",
    "            nn.Conv2d(last_inp_channels, config['DATASET']['NUM_CLASSES'],\n",
    "                      kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        )\n",
    "        \n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i],\n",
    "                                  num_channels_cur_layer[i],\n",
    "                                  3,\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(\n",
    "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=relu_inplace)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(\n",
    "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=relu_inplace)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "            modules.append(\n",
    "                HighResolutionModule(num_branches,\n",
    "                                     block,\n",
    "                                     num_blocks,\n",
    "                                     num_inchannels,\n",
    "                                     num_channels,\n",
    "                                     fuse_method,\n",
    "                                     reset_multi_scale_output)\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                if i < self.stage2_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition2[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                if i < self.stage3_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition3[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        x = self.stage4(x_list)\n",
    "\n",
    "        # Upsampling\n",
    "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
    "        x1 = F.interpolate(x[1], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "        x2 = F.interpolate(x[2], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "        x3 = F.interpolate(x[3], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        feats = torch.cat([x[0], x1, x2, x3], 1)\n",
    "\n",
    "        out_aux_seg = []\n",
    "\n",
    "        # ocr\n",
    "        out_aux = self.aux_head(feats)\n",
    "        # compute contrast feature\n",
    "        feats = self.conv3x3_ocr(feats)\n",
    "\n",
    "        context = self.ocr_gather_head(feats, out_aux)\n",
    "        feats = self.ocr_distri_head(feats, context)\n",
    "\n",
    "        out = self.cls_head(feats)\n",
    "\n",
    "        out_aux_seg.append(out_aux)\n",
    "        out_aux_seg.append(out)\n",
    "\n",
    "        return out_aux_seg\n",
    "\n",
    "    def init_weights(self, pretrained='',):\n",
    "        logger.info('=> init weights from normal distribution')\n",
    "        for name, m in self.named_modules():\n",
    "            if any(part in name for part in {'cls', 'aux', 'ocr'}):\n",
    "                # print('skipped', name)\n",
    "                continue\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "            elif isinstance(m, BatchNorm2d_class):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained, map_location={'cuda:0': 'cpu'})\n",
    "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k.replace('last_layer', 'aux_head').replace('model.', ''): v for k, v in pretrained_dict.items()}            \n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                               if k in model_dict.keys()}\n",
    "            # for k, _ in pretrained_dict.items():\n",
    "                # logger.info(\n",
    "                #     '=> loading {} pretrained model {}'.format(k, pretrained))\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "        elif pretrained:\n",
    "            raise RuntimeError('No such file {}'.format(pretrained))\n",
    "\n",
    "\n",
    "def get_seg_model(cfg, **kwargs):\n",
    "    model = HighResolutionNet(cfg, **kwargs)\n",
    "    model.init_weights(cfg['MODEL']['PRETRAINED'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, config, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label\n",
    "        )\n",
    "        self.config = config\n",
    "\n",
    "    def _forward(self, score, target):\n",
    "        ph, pw = score.size(2), score.size(3)\n",
    "        h, w = target.size(1), target.size(2)\n",
    "        if ph != h or pw != w:\n",
    "            score = F.interpolate(input=score, size=(\n",
    "                h, w), mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS)\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if self.config['MODEL']['NUM_OUTPUTS'] == 1:\n",
    "            score = [score]\n",
    "\n",
    "        weights = self.config['LOSS']['BALANCE_WEIGHTS']\n",
    "        assert len(weights) == len(score)\n",
    "\n",
    "        return sum([w * self._forward(x, target) for (w, x) in zip(weights, score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f18a9994-74aa-464a-9ae8-a0e8d7953e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def model_loss_define(yaml_path, train=True):\n",
    "    with open(yaml_path) as f:\n",
    "        cfg = yaml.load(f)\n",
    "\n",
    "    model = get_seg_model(cfg)\n",
    "    creterion = CrossEntropy(cfg)\n",
    "    return model, creterion\n",
    "\n",
    "model, creterion = model_loss_define('/opt/ml/code/seg_hrnet.yaml')\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "612550fc-a50f-47df-9840-aeef1f1f82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randint(0,1,size=(4,3,256,256)).float().to(device)\n",
    "result = model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6a1bb-524b-42f8-a6d3-810b0c6277ad",
   "metadata": {},
   "source": [
    "### 주의 사항\n",
    "### HRNet의 result는 단일 output이 아닙니다. \n",
    "### 아래 for 문을 통해 보실 수 있지만 두 개의 output을 가집니다. 또한 저희가 원하는 size가 아닌 1/4 heatmap으로 결과가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fa67ebd-8375-4526-b669-c21665ecb2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12, 64, 64])\n",
      "torch.Size([4, 12, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for output in result:\n",
    "    print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb153566-a183-4381-a4a6-b80bad0447f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(0,1,size=(4,256,256)).long().to(device)\n",
    "loss = creterion(result,target)\n",
    "print(loss.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693a7b0-da64-4dd3-b1e7-0298121d7235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
