#----------------------------------------------------------------------------------------------#
#------------------------------------------4/27 화---------------------------------------------#
#----------------------------------------------------------------------------------------------#

※모든 모델들이 epoch 9에서 가장 좋은 성능을 보임 (valid set 기준)
※하지만 그냥 epoch 10까지 전부 한 모델들 사용

1.
모델 : Efficientunet-b7
전처리 : X
batch_size : 2
epochs : 10
random_seed : 42
정확도 : 0.4095
학습 시간 (1epoch) : 8~9m
비고 :
    아직 loss값이 많이 낮음. epoch를 늘리면 과적합
    10epoch시에는 괜찮았고, 약 18epoch (중간에 취소 눌러서 까먹음)은 과적합이었음.
    ★10~18 사이의 적절한 epoch를 찾아야 함.


2.
모델 : Efficientunet-b7
전처리 : Resize(256)
batch_size : 4
epochs : 10
random_seed : 42
정확도 : 0.3820
학습 시간 (1epoch) : 3~4m
비고 :
    오히려 떨어짐.
    
    
3.
모델 : Efficientunet-b7
전처리 : CLAHE
batch_size : 4
epochs : 10
random_seed : 42
정확도 : 0.4042
학습 시간 (1epoch) : 7~8m
비고 :
    모든 이미지에 일일이 CLAHE를 입히니, 당연히 학습 시간이 증가
    Normalize도 하려고 했는데, 일단 /= 255 가 되어있어서 실패.
    ★시각화 결과로는 1번보다 훨씬 잘 예측함. 근데 왜 성능은 내려갔는지 모르겠음.
    
#----------------------------------------------------------------------------------------------#
#------------------------------------------4/28 수---------------------------------------------#
#----------------------------------------------------------------------------------------------#

※우연히 알아낸 사실 :
    256*256 으로 학습시킨 모델을 실수로 512*512로 테스트하여 제출함.
    그 후 잘못된 것을 깨닫고 256*256 으로 재테스트하여 제출했는데 결과가 똑같음. 
    => 그러면 512*512를 해서 512*512, 256*256 둘 다 해도 똑같은 결과가 아닐까?
    => 맞으면 최종 submission 때 512*512로 학습시켜서 256*256으로 검증하면 시간 절약 가능.
    
※토론 게시판에 unet은 배경을 잘 잡아낸다고 했는데, 맞는 말인 것 같다.
  그런데 배경과 객체를 기가막히게 잘 구분하지만, 객체간 구분을 할 줄 모른다.
  unet은 포기하고 deeplab 계열의 모델 사용이 적절해보임.

1.
모델 : Efficientunet-b7
전처리 : (원본, 수평 뒤집기, 수직 뒤집기, 랜덤 90도 회전) 으로 데이터 셋을 네 배로 증강 + Resize 256
batch_size : 8 (실제는 2)
epochs : 10
random_seed : 42
정확도 : 0.3223
학습 시간 (1epoch) : 11~12m
비고 :


2.
모델 : deeplabv3_resnet101
전처리 : Resize(256), Normalize
batch_size : 4
epochs : 20
random_seed : 42
정확도 : 0.5453
학습 시간 (1epoch) : 3~4m
비고 :
    unet이랑 비교가 안됨. 배경은 물론이고 객체까지 전부 잘 잡아줌.
    정확도가 train과 valid 모두 계속 상승. 과적합 기준을 어디로 해야할지 모르겠음 (일단 ES기준을 0.5로 잡고 20epoch만 돌림)
    
    
3.
모델 : deeplabv3_resnet101
전처리 : Resize(256), Normalize, Augmentation (Hor, Ver, Rot) => 4배로 증강
batch_size : 4 (사실상 16)
epochs : 14
random_seed : 42
정확도 : 0.5462 ★
학습 시간 (1epoch) : 12~13m
비고 :
    과적합이 빨리 되지만 성능은 향상.